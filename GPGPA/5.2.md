# 5.2 表达并行性的其他方式

**细粒度工作队列**。Kim 和 Batten [2014] 提议为 GPU 中的每个 SIMT 核心添加一个细粒度硬件工作队列。他们利用了这样一个观点：对于不规则的 GPGPU 程序，使用数据驱动的方法在软件中实现通常能够获得最佳性能。在数据驱动的方法中，工作会根据线程动态生成并在线程间进行平衡，而与之相对的拓扑方法则会启动固定数量的线程——其中许多线程不会执行有用的工作。数据驱动的方法有潜力提高工作效率和负载平衡，但如果没有广泛的软件优化，可能会导致性能不佳。本文提出了一个带有片上硬件工作队列的方案，支持在核心内部和跨核心之间进行负载平衡。他们采用了一种线程等待机制，并在一定间隔内重新平衡线程生成的任务。他们在 lonestar GPU 基准测试套件的各种不规则应用实现中评估了他们的硬件机制，这些实现既利用了拓扑方法，也利用了数据驱动的工作分配。

片上硬件工作队列解决了数据驱动软件工作队列的两个主要问题：(1) 当线程推送生成的工作时，内存系统中的争用；(2) 由于基于线程 ID 静态划分工作而导致的负载平衡差。不依赖于静态划分的软件实现在线程推送和拉取时都会遇到内存争用问题。静态划分工作可以解决拉取时的争用问题。硬件工作队列分布在多个结构中，减少了争用。它通过在工作生成之前动态重新分配工作到线程来改善负载平衡，防止线程空闲。作者为从硬件队列推送和拉取添加了特殊的 ISA 指令。核心中的每个通道都被分配了一个小的单端口 SRAM，用作特定通道使用和生成的工作 ID 的存储。

该论文提出了基于间隔和基于需求驱动（仅在推送/拉取请求时重新分配）的两种工作再分配方法，并深入评估了前者。基于间隔的方法根据简单阈值或更复杂的排序方式进行工作再分配。阈值方法将工作量超过阈值的通道分类为贪婪（工作过多），将工作量低于阈值的通道分类为需要（工作不足）。然后通过排序过程将工作从贪婪的存储库重新分配到需要的存储库。基于排序的技术更为复杂，但由于所有需要的存储库也可以向其他需要的存储库贡献工作，因此实现了更好的负载平衡。他们的技术还包括一个全局排序机制，可用于在核心之间分配工作。此外，该架构还支持硬件工作队列的虚拟化，使其可扩展到生成的动态工作量超过硬件结构容量的工作负载。

**嵌套并行模式的编程**。Lee 等人 [2014a] 提出了一种在 GPU 上对嵌套并行模式的局部感知映射，该映射基于这样一个观察结果：对于嵌套并行计算到 GPU 线程，并不存在一种普遍最优的映射。具有嵌套并行性的算法（如 map/reduce 操作）可以根据 GPU 程序的编写方式，在不同级别上暴露其并行性。作者利用了在 GPU 上对嵌套并行映射的三种泛化：

- 一维映射，它将顺序程序的外层循环并行化；
- 线程块/线程映射，它将顺序程序的外层循环的每一次迭代分配到一个线程块中，并在线程块内并行化内层模式；
- 基于 warp 的映射，它将外层循环的每一次迭代分配到一个 warp，并在 warp 中并行化内层模式。

这项工作提出了一个自动编译框架，该框架根据嵌套模式中的局部性和暴露的并行程度生成预测性能分数，以选择最适合一组常见嵌套并行模式的映射方式。这些模式包括诸如 map、reduce、foreach、filter 等集合操作。该框架尝试将线程映射到集合上每个元素的操作。该框架通过首先将应用程序中的每个嵌套级别分配给一个维度（x、y、z 等）来处理模式的嵌套。一个双重嵌套模式（即包含 reduce 的 map）有两个维度。然后，映射确定在 CUDA 线程块中给定维度中的线程数量。在设置了维度和线程块的大小之后，该框架进一步通过线程跨度和分裂的概念为每个线程分配多个元素，从而控制内核中的并行程度。在二维内核（即两个模式嵌套级别）中，如果每个维度都被分配为 span(1)，则内核中启动的每个线程仅负责对集合中的一个元素进行操作。这种映射方式暴露了最大的并行程度。相反，span(all) 表示每个线程对集合中的所有元素进行操作。跨度可以是介于（1）和（all）之间的任何数字。span(all) 在两种特殊情况下使用：一种是直到内核启动后才得知维度的大小（例如，当内层模式中操作的元素数量是动态确定的），另一种是模式需要同步（例如，reduce 操作）。

由于所有元素的跨度(span(all))可能会严重限制可利用的并行性，从而导致GPU资源未得到充分利用，因此该框架还提供了"分割"的概念。分割(split(2))表示每个线程在给定维度上处理一半的元素（可以理解为span(all)/2）。当使用分割时，框架会启动第二个内核（称为合并内核）来汇总各个分割的结果，产生的结果与内核使用span(all)进行分区时的结果相同。

为了选择每个维度的块大小以及每个维度的分割/跨度，框架采用了一种基于硬约束和软约束的评分算法。该算法搜索整个搜索空间中所有可能的维度、块大小和跨度。搜索空间相对于循环嵌套的层级是指数级的。然而，指数的底数少于100，典型的内核包含少于3个层级。因此，该空间可以在几秒钟内完全搜索。该搜索会剔除违反硬约束的配置——即那些导致错误执行的配置，例如，块中线程的最大数量过高。它会对软约束分配加权评分，例如确保模式的顺序内存访问被分配到x维度，以改善内存合并。

该框架还执行两种常见的GPU优化：预分配内存而不是在嵌套内核中动态分配全局内存，以及在确定将数据预取到共享内存对嵌套模式有利时使用共享内存。结果表明，自动生成的代码在性能上与专业调优的代码具有竞争力。

**动态并行性**。Wang 和 Yalamanchili [2014] 对在 Kepler GPU 硬件上使用 CUDA 动态并行性的开销进行了表征，并发现这些开销可能相当大。具体而言，他们识别了几个关键问题，这些问题限制了他们研究的工作负载的效率。首先，应用程序使用了大量设备启动的内核。其次，每个内核通常只有 40 个线程（略多于一个 warp）。第三，尽管每个动态内核中执行的代码相似，但启动配置不同，导致内核配置信息存储的开销很大。最后，为了实现并发性，设备启动的内核被放置在单独的流中，以利用 Kepler 支持的 32 个并行硬件队列。他们发现这些因素结合在一起，导致了非常低的利用率。

Wang 等人 [2016a] 随后提出了动态线程块启动（DTBL），修改了 CUDA 编程模型，以使设备启动的内核能够共享硬件队列资源，从而实现更大的并行性和更好的 GPU 硬件利用率。他们提案的关键在于使动态启动的内核能够与运行相同代码的现有内核聚合在一起。这是通过维护一个聚合线程块的链接列表来实现的，修改后的硬件在启动内核时会使用该列表。他们通过修改 GPGPU-Sim 进行评估，发现 DTBL 的性能比 CDP 提高了 1.4 倍，比高度优化的不使用 CDP 的 CUDA 版本提高了 1.2 倍。

Wang 等人 [2016b] 接着探讨了动态启动的线程块被调度到哪个 SM 的影响。他们发现，通过鼓励子线程块被调度到与父 SM 相同的 SM 上，同时考虑跨 SM 的工作负载分布，他们能够将性能提高 27%，与原始的轮询分配机制相比。
