### 第1章 概论

#### 1.1 计算加速器的格局

在过去的几十年中，每一代计算系统的性能和性价比都呈指数级增长。这一趋势的背后是晶体管尺寸的缩小、硬件架构的改进、编译器技术的进步以及算法的优化。据估计，其中约一半的性能提升归功于晶体管尺寸的缩小，这使得设备运行速度更快。然而，自2005年左右以来，晶体管的缩放不再遵循经典的“登纳德缩放”规则（Dennard Scaling）。一个关键的后果是，时钟频率的提升速度显著减慢。

为了继续提升性能，研究人员和工业界开始寻找更高效的硬件架构。通过利用硬件专用化，可以在能效上实现高达500倍的提升。Hameed等人指出，实现这种能效提升的关键因素包括：转向矢量硬件以消除指令处理的开销，以及引入复杂操作以减少对大型存储器（如寄存器文件）的访问。

计算机架构师如今面临的挑战是如何在专用硬件的能效提升与支持多种程序所需的灵活性之间找到平衡。专用加速器的一个新兴例子是用于支持深度神经网络的硬件，例如谷歌的张量处理单元（TPU）。尽管机器学习可能占据大量计算资源并迁移到专用硬件上，我们认为仍需要高效支持用传统编程语言编写的程序。GPU计算的一个重要特点是其硬件和软件的通用性，与专用加速器相比，现代GPU在能效上可以高出一个数量级。

#### 1.2 GPU硬件基础

首次接触GPU的人常常会问，GPU是否会最终完全取代CPU。这似乎不太可能。在当前的系统中，GPU并不是一个独立的计算设备，而是与CPU结合使用。CPU负责启动GPU上的计算任务，并在计算开始和结束时与GPU进行数据交换。一个典型的应用程序首先在CPU上运行，CPU部分会分配和初始化一些数据结构。对于较旧的独立GPU（如NVIDIA和AMD的早期产品），CPU部分通常会在CPU和GPU内存中分配空间，并协调数据从CPU内存到GPU内存的传输。对于最近的独立GPU（如NVIDIA的Pascal架构），软件和硬件支持可以自动传输数据，这通过统一内存实现。对于集成GPU，只需要执行计算启动的最后一步。

一个现代GPU由许多核心组成，如NVIDIA所称的流式多处理器（Streaming Multiprocessors，SM）或AMD所称的计算单元（Compute Units）。每个GPU核心执行一个与启动内核对应的单指令多线程（SIMT）程序。每个核心可以运行数千个线程，这些线程可以通过一个称为共享内存的线程存储器进行通信，并使用快速的屏障操作进行同步。每个核心通常包含一级指令和数据缓存，这些缓存作为带宽过滤器，减少了发送到内存系统的流量。

为了保持高计算吞吐量，需要平衡高计算吞吐量和高内存带宽。这又需要内存的并行性。在GPU中，这种并行性是通过包含多个内存通道来实现的。每个内存通道通常与一个内存分区相关联，其中一部分最后一级缓存位于一个存储分区中。GPU核心和存储分区通过片上互连网络（如交叉开关）连接，其他可能的组织方式包括AMD所采用的环形网络。

在一个典型的系统中，数据从CPU传递到GPU，GPU执行计算后将结果返回给CPU。这通常通过PCIe总线或其他高速接口完成。整个过程中，CPU和GPU之间的数据传输是一个关键步骤，需要高效管理以减少延迟和带宽瓶颈对性能的影响。

#### 1.3 GPU简史

本节简要描述了GPU的发展历史。计算机图形学起源于20世纪60年代，早期视频卡仅支持文本显示。随着时间的推移，视频卡逐渐支持2D和3D加速，早期的3D图形处理器如NVIDIA的GeForce 256相对固定功能。NVIDIA在2001年引入了顶点着色器和像素着色器，AMD则在GeForce 3中引入了这些功能。研究人员很快学会如何使用这些早期GPU通过将矩阵数据映射到纹理并应用着色器来实现线性代数运算。随后，学术界的工作开始探索如何将一般目的计算映射到GPU上，使得程序员无需了解图形知识即可进行编程。这些努力激发了GPU制造商直接支持一般目的计算的兴趣，NVIDIA的GeForce 8系列是第一个商业产品，引入了几个创新，包括从着色器中写入任意内存地址的能力和用于限制片外带宽的划痕内存。后续改进包括在NVIDIA的Fermi架构中启用读写数据的缓存。AMD的Fusion架构将CPU和GPU集成在同一芯片上，动态并行性可以在GPU本身上启动线程。最近，NVIDIA的Volta引入了专门针对机器学习加速的Tensor Core功能。

#### 1.4 书籍结构

本书的其余章节组织如下：

- **第2章 编程模型**：提供足够的背景知识，使那些没有GPU编程经验的人能够理解后续章节的讨论。简要介绍GPU编程模型、代码开发流程和编译流程。

- **第3章 SIMT核心：指令和寄存器数据流**：深入探讨GPU计算核心的架构，逐步构建对支持高吞吐量和灵活编程模型的权衡的深入理解。

- **第4章 内存系统**：探讨GPU内存系统，包括核心内的一级缓存和存储分区的内部组织。理解GPU内存系统至关重要，因为GPU上的计算通常受到片外内存带宽的限制。

- **第5章 GPU计算架构的跨研究主题**：总结那些不容易归入第3章或第4章的其他研究主题。

这本书为那些希望深入了解GPU架构以及如何改进这些GPU架构的研究人员提供了宝贵的资源。
