### 第1章 低层次细节的重要性

在本节中，我们通过一个实际案例来说明对架构的深入理解如何帮助开发人员在某些特定场景中实现显著的性能提升，尽管这需要付出相当大的开发努力。

深入优化代码以适应目标架构的努力往往不成比例。这种方法通常需要编写内联 PTX 汇编代码，甚至在极端情况下，需要修补二进制代码，以追求编译器不会生成的特定 SASS 汇编代码，遵循未公开的指令编码格式，而 NVIDIA 的工具链无法提供任何支持。

这种优化是否值得付出努力是一个核心问题，但最终只有您自己可以根据您独特的环境和对性能的迫切需求来判断。对于大多数 GPU 软件开发人员来说，答案是否定的：

- 如果 NVIDIA 提供的成熟库（例如 cuBlas、cuFFT、cuSparse、cuRand、cuDNN 等）涵盖了所需的计算功能，则获得的性能在大多数情况下已接近理想；
- 在其他应用程序中，开发人员编写 CUDA 代码时，如果源代码编写得足够好，NVCC 通常会生成高效的机器代码。

只有在少数情况下，对性能的极致追求才值得进行极端的低层次优化。大量研究传统上专注于理解 GPU 指令编码 [4, 5, 6]，以改进计算内核的性能 [7, 8, 9]。我们之前对 Volta [2] 的研究也提供了这样的例子：我们修补了编译器生成的代码，使其更好地利用寄存器缓存，从而实现了 15% 的浮点运算吞吐量提升。

这一次，我们展示了对 Turing 指令的理解如何使设计者优化一个常见的线性代数函数（即 BLAS ?axpy），其单精度操作数的库实现包含限制为 64 位宽度的内存访问操作。我们展示了一个简单的替换方法，使用 128 位向量访问，显著提升了性能（见图 1.1）。

我们选择的 ?axpy 工作负载执行按比例缩放的向量-向量逐元素求和，即：

\[
y_i = \alpha \cdot x_i + y_i \quad \text{其中} \quad i = 0, 1, \ldots, n-1
\]

其中 \( \alpha \) 是比例因子。该工作负载的算术强度显然较低，因此它是内存受限的。这意味着其对全局内存访问效率的任何提升都会直接转化为整体加速。

在 CPU 上用 C 语言实现此工作负载的最直接方法是调用 BLAS 函数 `cblas_?axpy`（其中‘?’是操作数类型的占位符，即 s、d、c 或 z，分别对应单精度或双精度、实数或复数操作数）。在 CUDA 中，对应的函数是 NVIDIA cuBlas 库中的 `cublas?axpy`。为简化起见，我们仅关注其单精度变体 `cublasSaxpy`。

在我们的分析中，函数 `cublasSaxpy` 调用了 `axpy_kernel_val`，其在 CUDA SDK 10.0 版本中的单精度实现包含的加载和存储指令（从/到全局内存）的宽度不超过 64 位。以下是其中一个实现的摘录：

```c
Function: void axpy_kernel_val<float2, float2, 0>(
|...|
|/*01f0*/|LDG.E.64.SYS R2, [R2] ;|
|/*0200*/|LDG.E.64.SYS R8, [R4] ;|
|...|
|/*0330*/|LDG.E.64.SYS R2, [R2] ;|
|/*0340*/|LDG.E.64.SYS R8, [R4] ;|
|...|
```

这种访问宽度在 Turing 上是次优的，特别是考虑到：

1. 根据 NVIDIA 公开信息 [10, 3]，Turing 每个 SM 的加载/存储单元数量仅为 Volta 的一半（16 对比 32）；
2. T4 设备支持的每个 SM 的线程数量仅为 V100 设备的一半（1,024 对比 2,048），因此仅通过增加线程块数量更难饱和可用的内存带宽。

因此，每条指令加载更宽的字是增加内存访问吞吐量的有效策略。我们在改进的 Saxpy 内核中实现了这一点，它使用了 128 位向量化的内存访问指令：

```c
global void improved_Saxpy(
    float *d_y, const float *d_x, const float alpha, const uint32_t arraySize)
{
    // 每个线程一次处理 4 个元素
    uint32_t tid = (threadIdx.x + blockIdx.x * blockDim.x) * 4;
    // 所有 GPU 上线程可以一次处理的元素数量
    uint32_t dim = gridDim.x * blockDim.x * 4;
    for (uint32_t i = tid; i < arraySize; i += dim)
    {
        asm volatile ("{\t\n"
            // 寄存器用于存储输入操作数
            ".reg .f32 a1, b1, c1, d1;\n\t"
            ".reg .f32 a2, b2, c2, d2;\n\t"
            // 使用向量化的 128 位加载指令
            "ld.global.v4.f32 {a1, b1, c1, d1}, [%0];\n\t"
            "ld.global.v4.f32 {a2, b2, c2, d2}, [%1];\n\t"
            // 执行核心数学运算
            "fma.rn.f32 a2, a1, %2, a2;\n\t"
            "fma.rn.f32 b2, b1, %2, b2;\n\t"
            "fma.rn.f32 c2, c1, %2, c2;\n\t"
            "fma.rn.f32 d2, d1, %2, d2;\n\t"
            // 使用向量化的 128 位写入指令存储结果
            "st.global.v4.f32 [%1], {a2, b2, c2, d2};\n\t"
            "}"
            : "+f"(d_y[i]), "+f"(d_x[i])
            : "f"(alpha)
            : "memory");
    }
}
```

上述代码中内联的 PTX 汇编代码明显使用了 128 位宽的加载和存储指令 `ld.global.v4.f32` 和 `st.global.v4.f32`，一次可以传输四个单精度浮点值的向量。（为了简化和简洁起见，我们的实现忽略了数组大小不是 4 的倍数的情况。）

对相应 SASS 代码的检查（由 NVCC 生成）确认全局内存指令为 128 位宽：

```c
|...|
|/*00d0*/|LDG.E.128.SYS R8, [R8] ;|
|/*00e0*/|LDG.E.128.SYS R4, [R2] ;|
|...|
|/*0110*/|FFMA R4, R8, c[0x0][0x170], R4 ;|
|/*0120*/|FFMA R5, R9, c[0x0][0x170], R5 ;|
|/*0130*/|FFMA R6, R10, c[0x0][0x170], R6 ;|
|/*0140*/|FFMA R7, R11, c[0x0][0x170], R7 ;|
|/*0150*/|STG.E.128.SYS [R2], R4 ;|
|...|
```

这种改进的 `improved_Saxpy` 代码的性能明显高于 `cublasSaxpy`（见图 1.1），除了对于微小数组（<20 KiB），并且随着数组大小的增加，其性能几乎翻倍。

总之，通过这个例子，我们展示了只有对 Turing 指令集有深入了解并且对架构性能行为有架构级理解的软件设计者才能获得的优化机会：这些目标正是本报告的主题。
