4.3 New Tensor Core instructions

4.4 Arithmetic performance

4.5 Performance throttling

5 Conclusions

### 4.3 新的Tensor Core指令

Turing架构通过支持更广泛的运算类型，对Tensor Cores进行了更新。具体来说，Tensor Cores在Volta中最初被设计为在半精度浮点运算数上执行矩阵运算时提供高吞吐量；在Turing中，Tensor Cores增加了对短整数运算数的支持：包括int8、int4和int1。

此外，Turing还引入了新的指令，使得矩阵运算的表达更加简洁。为了说明这一点，我们将比较针对Volta和Turing架构，由编译器为相同的warp级原语`wmma::mma_sync()`生成的代码。

当目标是Volta时，NVCC将该原语的一个示例调用编译为以下16条HMMA.884.F32.F32.*指令：

```assembly
HMMA.884.F32.F32.STEP0 R8, R26.reuse.COL, R16.reuse.COL, R8;
HMMA.884.F32.F32.STEP1 R10, R26.reuse.COL, R16.reuse.COL, R10;
HMMA.884.F32.F32.STEP2 R4, R26.reuse.COL, R16.reuse.COL, R4;
HMMA.884.F32.F32.STEP3 R6, R26.COL, R16.COL, R6;
HMMA.884.F32.F32.STEP0 R8, R20.reuse.COL, R18.reuse.COL, R8;
HMMA.884.F32.F32.STEP1 R10, R20.reuse.COL, R18.reuse.COL, R10;
HMMA.884.F32.F32.STEP2 R4, R20.reuse.COL, R18.reuse.COL, R4;
HMMA.884.F32.F32.STEP3 R6, R20.COL, R18.COL, R6;
HMMA.884.F32.F32.STEP0 R8, R22.reuse.COL, R12.reuse.COL, R8;
HMMA.884.F32.F32.STEP1 R10, R22.reuse.COL, R12.reuse.COL, R10;
HMMA.884.F32.F32.STEP2 R4, R22.reuse.COL, R12.reuse.COL, R4;
HMMA.884.F32.F32.STEP3 R6, R22.COL, R12.COL, R6;
HMMA.884.F32.F32.STEP0 R8, R2.reuse.COL, R14.reuse.COL, R8;
HMMA.884.F32.F32.STEP1 R10, R2.reuse.COL, R14.reuse.COL, R10;
HMMA.884.F32.F32.STEP2 R4, R2.reuse.COL, R14.reuse.COL, R4;
HMMA.884.F32.F32.STEP3 R6, R2.COL, R14.COL, R6;
```

当目标是Turing时，NVCC将相同的原语调用编译为仅4条新的HMMA指令，包含新的`.1688`后缀：

```assembly
HMMA.1688.F32 R8, R12, R22, R8;
HMMA.1688.F32 R4, R12, R23, R4;
HMMA.1688.F32 R8, R2, R24, R8;
HMMA.1688.F32 R4, R2, R25, R4;
```

### 4.4 算术性能

我们通过使用cuBLAS 10.1库中的函数和cutlass 1.2中的模板函数对矩阵-矩阵乘法进行基准测试，评估了在不同精度的浮点数和整数上的算术性能。我们在所有实验中报告了以TOPS（每秒万亿次操作）和TFLOPS（每秒万亿次浮点运算）为单位的算术吞吐量。在所有实验中，T4 GPU的时钟频率为1590 MHz。

在半精度、单精度和双精度浮点数上，cuBLAS的算术吞吐量高于cutlass。这是因为cuBLAS库针对Turing架构进行了特别优化。对于int8精度，cuBLAS 10.1提供了两个API：

- BLAS样式的扩展函数`cublasGemmEx`，它调用原生的CUDA核心实现；
- 新的轻量级函数`cublasLtMatmul`，它支持int8的原生TensorCore实现。

对于int8，`cublasLtMatmul`的吞吐量远高于`cublasGemmEx`。在撰写本文时，只有cutlass支持在NVIDIA GPU上进行int4和int1精度的矩阵乘法。

除了双精度之外，基准测试没有达到接近峰值的性能。对于int8和int4，cutlass的实现没有达到T4 GPU上50%的理论吞吐量（见图4.2）。

我们在表4.3中比较了T4和P4 GPU在不同精度的矩阵乘法上的算术吞吐量，两块板卡都运行在各自的最高频率（1590 MHz和1531 MHz）。T4 GPU在半精度和int8精度上享有更高的吞吐量，这得益于Tensor Cores的使用。

由于T4和P4 GPU具有相同数量的CUDA核心，我们在两块板卡上的矩阵乘法中测量了类似的算术吞吐量，对于双精度和单精度浮点数。需要注意的是，双精度性能受到可用的原生FP64核心数量较少的限制（每个SM只有两个），因为这两种架构都针对推理进行了优化，其中更频繁地使用低精度。

### 表4.3: 推理型GPU在浮点数和整数类型上的矩阵乘法算术吞吐量

|架构|T4|P4|
|---|---|---|
|双精度|253 GFLOPS|231 GFLOPS|
|单精度|7,174 GFLOPS|6,944 GFLOPS|
|半精度|41,616 GFLOPS|6,571 GFLOPS|
|int8精度|74,934 GOPS|24,172 GOPS|
|int4精度|114,384 GOPS|—|
|int1精度|552,230 GOPS|—|

### 4.5 性能限制

大多数 GPU 会采用时钟频率限制和/或功耗状态限制，以防止在工作负载特别繁重或散热不足时超出功耗或热设计功耗（TDP）限制。

我们的实验表明，小尺寸的 T4 和 P4 板卡（专为推理应用设计）在单位功耗下的频率表现优于其全尺寸的同类产品。然而，由于以下原因，它们比全尺寸的同类产品（如 K80、P100、V100 和 M60）更容易触发时钟频率限制：

- 它们的尺寸较小，限制了散热器的散热速率；
- 制造商设定的最大功耗限制较低（T4 和 P4 为 70W），而全尺寸板卡（如 K80、P100、V100 和 M60）的功耗限制通常为 250W 或更高。

#### 实验设置：所有 GPU 样品均采用被动散热。我们的 K80、P100、V100 和 M60 实验在 Dell PowerEdge C4130 服务器上进行，这些服务器是经过 NVIDIA Tesla 认证的。我们的 T4 和 P4 实验在 HPE Proliant DL360 Gen9 服务器上进行。该服务器型号未出现在 NVIDIA 的 Tesla 认证服务器目录中。GPU 的功耗和热性能也取决于承载它的服务器，可能在非认证服务器上表现不佳。紧随我们所用服务器型号之后的服务器（HPE Proliant DL360 Gen10）是经过 Tesla 认证的，但在本文撰写时，我们无法安排升级。

在我们的实验中，我们能够通过基于 cuBLAS 矩阵乘法内核的基准测试一致地触发 T4 GPU 的时钟频率限制。在 T4 GPU 上，时钟频率限制触发的原因有两个：

- **功耗限制**：瞬时功耗超过了制造商设定的功耗限制（T4 GPU 为 70W）；
- **热限制**：GPU 达到了其最大工作温度（T4 卡为 85°C）。

与功耗限制相比，热限制会导致更严重的时钟频率降低。

#### 4.5.1 功耗限制

在 T4 和 P4 GPU 上，我们在基于 cuBLAS 的矩阵乘法实验中很早就观察到了功耗限制的触发。相比之下，V100、P100、M60 和 K80 GPU 几乎没有经历任何功耗限制，因为它们的实际功耗与功耗限制之间有很大的余地。

为了确认限制的原因，我们设计了一个实验，该实验调用 cuBLAS `<t>gemm` 内核，输入矩阵的大小逐渐增大。我们观察到，随着输入矩阵大小的增加，T4 GPU 超过其功耗限制的频率越来越高，时钟频率也越来越低。降低的时钟频率最终会损害整体算术吞吐量。见图 4.3。

在实验中，我们将 T4 卡的图形应用时钟频率设置为 1,590 MHz，并防止 GPU 温度超过 T4 GPU 的最大工作温度。我们记录了 T4 卡在半精度下计算 cuBLAS `<t>gemm` 时的时钟频率。

#### 4.5.2 热限制

我们通过一个基准测试来表征热限制，该测试反复启动一个 cuBLAS `<t>gemm` 内核，处理一个大型矩阵。我们观察到，当温度低于 85°C（T4 卡的最大工作温度）时，功耗限制会导致 T4 GPU 随着温度的升高而降低其图形时钟频率。一旦温度达到 85°C，热限制就会触发，除了功耗限制外，还会导致更大幅度的时钟频率降低，如图 4.4 所示。

#### 4.5.3 不同 GPU 设备上的功耗限制

我们通过记录所有卡在计算相同 cuBLAS Sgemm 内核的无尽重复时的图形时钟频率，比较了不同 GPU 的功耗限制行为，输入矩阵大小为 1024×1024。

我们注意到低功耗 GPU（例如 T4 和 P4）和全尺寸 GPU（如 K80、M60、P100、V100）之间存在显著差异。我们仅在 T4 和 P4 GPU 上观察到了时钟频率限制。这两款卡在实验开始时仅能在最初的几秒钟内以最高支持的时钟频率运行。随着温度的升高，时钟频率限制介入，时钟频率降低（见图 4.5）。

在全尺寸、全尺寸 GPU 上，我们无法将功耗提高到足以接近限制并触发限制的程度。

#### 实验设置：在所有实验中，我们将所有图形时钟设置为每个设备支持的最高值。我们关闭了所有可用的 AutoBoost 功能。我们还确保只有功耗限制处于活动状态。



### 第5章 结论

我们通过微基准测试更新了对Turing架构的剖析研究。我们揭示了Turing的架构细节，并将其与之前的NVIDIA架构进行了比较。

我们特别强调了T4和P4 GPU之间的比较：两者都是面向推理应用的低功耗、小尺寸板卡。T4基于Turing架构，而其前身P4基于Pascal架构。

我们发现，Turing采用了与Volta相同的指令编码方式，但扩展了Volta的指令集；它还引入了一种新的寄存器类型（统一寄存器），并在Tensor Cores上支持更多的操作数类型。这些新指令使得nvcc编译器能够在Turing上用更少的指令表达矩阵数学运算，与Volta相比。

T4 GPU在处理低精度操作数时，算术吞吐量显著高于P4。Turing的内存层次结构与Volta相似，某些缓存级别的大小有所不同。我们对这些差异进行了全面的考察。在指令编码、内存层次结构以及处理单元的行为方面，Turing和Volta代展现出连续性，并且与Kepler及更老的代相比，它们代表了一个显著的背离。

Turing延续了调度器与核心比率增长的趋势，这一比率从Kepler的1:48增长到Turing的1:16。这一趋势与指令吞吐量的增长相关。通过引入L0指令缓存，Turing和Volta缓解了与较长指令相关的惩罚。改进的L1数据缓存提供了更低的延迟和更高的带宽。新的替换策略在不使用共享内存时减少了缓存未命中率，从Pascal的4个单端口寄存器银行变为2个双端口银行，有助于防止银行冲突。

与Pascal P4 GPU相比，Turing T4 GPU在L1缓存和全局内存上提供了更高的带宽。T4 GPU在半精度、int8和int4矩阵乘法上具有更高的算术吞吐量，这归功于其改进的Tensor Cores。在单精度和双精度下，T4和P4 GPU表现出相似的性能，因为它们拥有相同数量的核心，并且以相似的频率运行。

利用我们对指令集编码的发现，软件设计者可以在二进制级别优化代码，甚至构建定制的SASS汇编器，以针对Turing生成更紧密调度的代码，从而实现更高的性能。凭借我们披露的内存层次结构信息，开发人员还可以通过选择与每个合适层级的缓存内存相匹配的工作集来优化代码，从而减少未命中率并提高整体性能。
